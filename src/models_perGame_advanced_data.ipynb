{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, merge and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8295, 51)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_game = pd.read_csv(Path('../data/per_game_data.csv'))\n",
    "advanced = pd.read_csv(Path('../data/advanced_data.csv'))\n",
    "advanced.drop(columns=['MP'], inplace=True)\n",
    "\n",
    "data = per_game.merge(advanced, on=['Player', 'Pos', 'Age', 'Tm', 'G', 'season', 'all_nba_1st_team'])\n",
    "data.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2121, 39)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['Player', 'Pos', 'Age', 'Tm', 'season'], inplace=True)\n",
    "data.drop(columns=['GS'], inplace=True)\n",
    "\n",
    "data = data[data.G > 40]\n",
    "data = data[data.MP > 25]\n",
    "\n",
    "data.drop(columns=['FG%', '2P%', '3P%', 'FT%'], inplace=True)\n",
    "data.drop(columns=['G', 'MP'], inplace=True)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data and scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['all_nba_1st_team'])\n",
    "y = data['all_nba_1st_team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=27, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1394,   27]), array([687,  13]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train), np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model without sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, y_train, estimator, grid, scoring, cv=10):\n",
    "    clf = GridSearchCV(estimator=estimator, param_grid=grid, scoring=scoring, cv=cv)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return clf.best_estimator_, clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, log_loss, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(estimator, X_test, y_test):\n",
    "    y_predicted = estimator.predict(X_test)\n",
    "\n",
    "    print('confusion matrix:')\n",
    "    print(confusion_matrix(y_test, y_predicted))\n",
    "    print('-------------------------')\n",
    "    print('classification report:')\n",
    "    print(classification_report(y_test, y_predicted))\n",
    "    print('-------------------------')\n",
    "    print('roc auc score:', roc_auc_score(y_test, y_predicted))\n",
    "    print('-------------------------')\n",
    "    print('Log loss:', log_loss(y_test, y_predicted))\n",
    "    print('-------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svc = {\n",
    "    'kernel': ['rbf'],\n",
    "    'C': [10**i for i in range(-5, 5)],\n",
    "    'gamma': ['scale', 'auto'] + [10**i for i in range(-3, 3)],\n",
    "    'probability': [True],\n",
    "    'random_state': [27]\n",
    "}\n",
    "\n",
    "grid_rfc = {\n",
    "    'n_estimators': np.linspace(start=50, stop=300, num=6, dtype=int),\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': np.linspace(start=10, stop=100, num=10, dtype=int),\n",
    "    'random_state': [27]\n",
    "}\n",
    "\n",
    "grid_gbc = {\n",
    "    'loss': ['deviance'],\n",
    "    'n_estimators': np.linspace(start=50, stop=300, num=6, dtype=int),\n",
    "    'max_depth': np.linspace(start=10, stop=100, num=10, dtype=int),\n",
    "    'max_features': [None, 'sqrt'],\n",
    "    'random_state': [27]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf', 'probability': True, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[680   7]\n",
      " [  8   5]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       687\n",
      "           1       0.42      0.38      0.40        13\n",
      "\n",
      "    accuracy                           0.98       700\n",
      "   macro avg       0.70      0.69      0.69       700\n",
      "weighted avg       0.98      0.98      0.98       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.6872130780427723\n",
      "-------------------------\n",
      "Log loss: 0.7401246330081032\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_svc, params = create_model(X_train, y_train, SVC(), grid_svc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 50, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[687   0]\n",
      " [ 11   2]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       687\n",
      "           1       1.00      0.15      0.27        13\n",
      "\n",
      "    accuracy                           0.98       700\n",
      "   macro avg       0.99      0.58      0.63       700\n",
      "weighted avg       0.98      0.98      0.98       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.5769230769230769\n",
      "-------------------------\n",
      "Log loss: 0.5427522004914546\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_rfc, params = create_model(X_train, y_train, RandomForestClassifier(), grid_rfc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'deviance', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 50, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[687   0]\n",
      " [ 10   3]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       687\n",
      "           1       1.00      0.23      0.38        13\n",
      "\n",
      "    accuracy                           0.99       700\n",
      "   macro avg       0.99      0.62      0.68       700\n",
      "weighted avg       0.99      0.99      0.98       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.6153846153846154\n",
      "-------------------------\n",
      "Log loss: 0.4934110913558679\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_gbc, params = create_model(X_train, y_train, GradientBoostingClassifier(), grid_gbc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_gbc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 1/4\n",
    "rus = RandomUnderSampler(random_state=27, sampling_strategy=ratio)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1394,   27]), array([108,  27]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train), np.bincount(y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf', 'probability': True, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[642  45]\n",
      " [  1  12]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       687\n",
      "           1       0.21      0.92      0.34        13\n",
      "\n",
      "    accuracy                           0.93       700\n",
      "   macro avg       0.60      0.93      0.65       700\n",
      "weighted avg       0.98      0.93      0.95       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.9287873698354048\n",
      "-------------------------\n",
      "Log loss: 2.2697424229289296\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_undersampling_svc, params = create_model(X_train_resampled, y_train_resampled, SVC(), grid_svc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_undersampling_svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 50, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[657  30]\n",
      " [  2  11]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       687\n",
      "           1       0.27      0.85      0.41        13\n",
      "\n",
      "    accuracy                           0.95       700\n",
      "   macro avg       0.63      0.90      0.69       700\n",
      "weighted avg       0.98      0.95      0.97       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.901242861941552\n",
      "-------------------------\n",
      "Log loss: 1.5789497608000693\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_undersampling_rfc, params = create_model(X_train_resampled, y_train_resampled, RandomForestClassifier(), grid_rfc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_undersampling_rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'deviance', 'max_depth': 10, 'max_features': None, 'n_estimators': 50, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[650  37]\n",
      " [  1  12]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       687\n",
      "           1       0.24      0.92      0.39        13\n",
      "\n",
      "    accuracy                           0.95       700\n",
      "   macro avg       0.62      0.93      0.68       700\n",
      "weighted avg       0.98      0.95      0.96       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.9346097861381704\n",
      "-------------------------\n",
      "Log loss: 1.875004411587891\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_undersampling_gbc, params = create_model(X_train_resampled, y_train_resampled, GradientBoostingClassifier(), grid_gbc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_undersampling_gbc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 1/4\n",
    "ros = RandomOverSampler(random_state=27, sampling_strategy=ratio)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1394,   27]), array([1394,  348]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train), np.bincount(y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[674  13]\n",
      " [  4   9]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       687\n",
      "           1       0.41      0.69      0.51        13\n",
      "\n",
      "    accuracy                           0.98       700\n",
      "   macro avg       0.70      0.84      0.75       700\n",
      "weighted avg       0.98      0.98      0.98       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.8366924196618519\n",
      "-------------------------\n",
      "Log loss: 0.8388137049715354\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_oversampling_svc, params = create_model(X_train_resampled, y_train_resampled, SVC(), grid_svc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_oversampling_svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 50, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[687   0]\n",
      " [ 10   3]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       687\n",
      "           1       1.00      0.23      0.38        13\n",
      "\n",
      "    accuracy                           0.99       700\n",
      "   macro avg       0.99      0.62      0.68       700\n",
      "weighted avg       0.99      0.99      0.98       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.6153846153846154\n",
      "-------------------------\n",
      "Log loss: 0.4934110913558678\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_oversampling_rfc, params = create_model(X_train_resampled, y_train_resampled, RandomForestClassifier(), grid_rfc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_oversampling_rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'deviance', 'max_depth': 10, 'max_features': None, 'n_estimators': 50, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[680   7]\n",
      " [ 10   3]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       687\n",
      "           1       0.30      0.23      0.26        13\n",
      "\n",
      "    accuracy                           0.98       700\n",
      "   macro avg       0.64      0.61      0.62       700\n",
      "weighted avg       0.97      0.98      0.97       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.6102900011196954\n",
      "-------------------------\n",
      "Log loss: 0.8388068512792766\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_oversampling_gbc, params = create_model(X_train_resampled, y_train_resampled, GradientBoostingClassifier(), grid_gbc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_oversampling_gbc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=27, k_neighbors=5)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1394,   27]), array([1394, 1394]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train), np.bincount(y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[644  43]\n",
      " [  2  11]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       687\n",
      "           1       0.20      0.85      0.33        13\n",
      "\n",
      "    accuracy                           0.94       700\n",
      "   macro avg       0.60      0.89      0.65       700\n",
      "weighted avg       0.98      0.94      0.95       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.8917814354495578\n",
      "-------------------------\n",
      "Log loss: 2.2203990292292564\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_smote_svc, params = create_model(X_train_resampled, y_train_resampled, SVC(), grid_svc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_smote_svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 200, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[671  16]\n",
      " [  3  10]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       687\n",
      "           1       0.38      0.77      0.51        13\n",
      "\n",
      "    accuracy                           0.97       700\n",
      "   macro avg       0.69      0.87      0.75       700\n",
      "weighted avg       0.98      0.97      0.98       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.8729705520098533\n",
      "-------------------------\n",
      "Log loss: 0.9374993500888381\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_smote_rfc, params = create_model(X_train_resampled, y_train_resampled, RandomForestClassifier(), grid_rfc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_smote_rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'deviance', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 300, 'random_state': 27}\n",
      "confusion matrix:\n",
      "[[681   6]\n",
      " [ 10   3]]\n",
      "-------------------------\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       687\n",
      "           1       0.33      0.23      0.27        13\n",
      "\n",
      "    accuracy                           0.98       700\n",
      "   macro avg       0.66      0.61      0.63       700\n",
      "weighted avg       0.97      0.98      0.98       700\n",
      "\n",
      "-------------------------\n",
      "roc auc score: 0.6110178031575412\n",
      "-------------------------\n",
      "Log loss: 0.7894645998616469\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_smote_gbc, params = create_model(X_train_resampled, y_train_resampled, GradientBoostingClassifier(), grid_gbc, scoring='recall', cv=10)\n",
    "\n",
    "print(params)\n",
    "\n",
    "evaluate_model(model_smote_gbc, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit69334052dc134bb69c4c72fd0130cada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
